{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e349d3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 21:02:48.017430: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-10 21:02:48.017463: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "#import cv2\n",
    "import shutil\n",
    "import random as rn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61fbd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =\"Flowers-Dataset/flowers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053523b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dandelion', 'sunflower', 'tulip', 'rose', 'daisy']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6d35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 22\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c846c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3324dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a41e69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(data_dir,target_size=(64,64),class_mode='categorical',batch_size=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688e5d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=test_datagen.flow_from_directory(data_dir,target_size=(64,64),class_mode='categorical',batch_size=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec50636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b02ce16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 files belonging to 5 classes.\n",
      "Using 3454 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 21:02:50.096933: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-10-10 21:02:50.096955: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (shriram-ASUS-TUF-LINUX): /proc/driver/nvidia/version does not exist\n",
      "2022-10-10 21:02:50.098146: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fba8f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 files belonging to 5 classes.\n",
      "Using 863 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb5dccfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8173f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4511282",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(img_height, \n",
    "                                                              img_width,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "918d7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.3),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(512, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb452d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3e1de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 49s 305ms/step - loss: 1.2778 - accuracy: 0.4441 - val_loss: 1.2945 - val_accuracy: 0.4936\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 48s 303ms/step - loss: 1.0307 - accuracy: 0.5843 - val_loss: 0.9324 - val_accuracy: 0.6130\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.9500 - accuracy: 0.6213 - val_loss: 0.9565 - val_accuracy: 0.6072\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.9062 - accuracy: 0.6465 - val_loss: 0.8913 - val_accuracy: 0.6431\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.8215 - accuracy: 0.6726 - val_loss: 0.8471 - val_accuracy: 0.6790\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.8042 - accuracy: 0.6896 - val_loss: 0.7350 - val_accuracy: 0.7045\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 48s 303ms/step - loss: 0.7729 - accuracy: 0.6989 - val_loss: 0.8984 - val_accuracy: 0.6443\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.7502 - accuracy: 0.7105 - val_loss: 0.7270 - val_accuracy: 0.7138\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.7079 - accuracy: 0.7279 - val_loss: 0.9064 - val_accuracy: 0.6767\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 47s 302ms/step - loss: 0.7091 - accuracy: 0.7252 - val_loss: 0.7706 - val_accuracy: 0.6952\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 48s 305ms/step - loss: 0.6663 - accuracy: 0.7458 - val_loss: 0.7167 - val_accuracy: 0.7497\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 47s 299ms/step - loss: 0.6671 - accuracy: 0.7420 - val_loss: 0.6801 - val_accuracy: 0.7625\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 47s 299ms/step - loss: 0.6424 - accuracy: 0.7496 - val_loss: 0.7086 - val_accuracy: 0.7439\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 48s 307ms/step - loss: 0.6124 - accuracy: 0.7687 - val_loss: 0.6728 - val_accuracy: 0.7451\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.5872 - accuracy: 0.7797 - val_loss: 0.7043 - val_accuracy: 0.7567\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.5655 - accuracy: 0.7788 - val_loss: 0.7963 - val_accuracy: 0.7207\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.5421 - accuracy: 0.7875 - val_loss: 0.6882 - val_accuracy: 0.7613\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 47s 302ms/step - loss: 0.5437 - accuracy: 0.7910 - val_loss: 0.6691 - val_accuracy: 0.7381\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.4958 - accuracy: 0.8037 - val_loss: 0.7025 - val_accuracy: 0.7474\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.5020 - accuracy: 0.8107 - val_loss: 0.6935 - val_accuracy: 0.7486\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.4486 - accuracy: 0.8246 - val_loss: 0.8407 - val_accuracy: 0.7404\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 47s 299ms/step - loss: 0.4445 - accuracy: 0.8263 - val_loss: 0.7833 - val_accuracy: 0.7520\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 47s 302ms/step - loss: 0.4290 - accuracy: 0.8301 - val_loss: 0.6820 - val_accuracy: 0.7798\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 47s 302ms/step - loss: 0.4025 - accuracy: 0.8393 - val_loss: 0.6825 - val_accuracy: 0.7659\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.3811 - accuracy: 0.8541 - val_loss: 0.7443 - val_accuracy: 0.7659\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.3730 - accuracy: 0.8625 - val_loss: 0.6575 - val_accuracy: 0.7798\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.3528 - accuracy: 0.8683 - val_loss: 0.6288 - val_accuracy: 0.7775\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.3669 - accuracy: 0.8558 - val_loss: 0.6548 - val_accuracy: 0.7914\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 48s 307ms/step - loss: 0.3529 - accuracy: 0.8662 - val_loss: 0.7351 - val_accuracy: 0.7601\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 47s 300ms/step - loss: 0.3182 - accuracy: 0.8862 - val_loss: 0.7456 - val_accuracy: 0.7798\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 47s 297ms/step - loss: 0.3336 - accuracy: 0.8752 - val_loss: 0.6824 - val_accuracy: 0.7787\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 47s 299ms/step - loss: 0.3076 - accuracy: 0.8830 - val_loss: 0.6477 - val_accuracy: 0.7984\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.2876 - accuracy: 0.8943 - val_loss: 0.9211 - val_accuracy: 0.7509\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 47s 302ms/step - loss: 0.2843 - accuracy: 0.8917 - val_loss: 0.7277 - val_accuracy: 0.7879\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 47s 299ms/step - loss: 0.2672 - accuracy: 0.8981 - val_loss: 0.7895 - val_accuracy: 0.7903\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.2663 - accuracy: 0.8937 - val_loss: 0.8062 - val_accuracy: 0.7787\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 47s 301ms/step - loss: 0.2448 - accuracy: 0.9157 - val_loss: 0.8473 - val_accuracy: 0.7856\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 48s 303ms/step - loss: 0.2447 - accuracy: 0.9024 - val_loss: 0.7994 - val_accuracy: 0.7845\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 47s 302ms/step - loss: 0.2397 - accuracy: 0.9105 - val_loss: 0.8078 - val_accuracy: 0.7984\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 48s 305ms/step - loss: 0.2505 - accuracy: 0.9108 - val_loss: 0.8589 - val_accuracy: 0.7984\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 52s 334ms/step - loss: 0.2382 - accuracy: 0.9131 - val_loss: 0.7778 - val_accuracy: 0.7879\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 50s 316ms/step - loss: 0.1862 - accuracy: 0.9328 - val_loss: 0.8604 - val_accuracy: 0.7683\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 50s 319ms/step - loss: 0.2266 - accuracy: 0.9105 - val_loss: 0.7679 - val_accuracy: 0.8019\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 48s 305ms/step - loss: 0.2146 - accuracy: 0.9172 - val_loss: 0.7584 - val_accuracy: 0.7914\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 48s 305ms/step - loss: 0.2032 - accuracy: 0.9186 - val_loss: 0.8749 - val_accuracy: 0.7914\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 48s 307ms/step - loss: 0.2073 - accuracy: 0.9233 - val_loss: 0.8090 - val_accuracy: 0.7984\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 48s 303ms/step - loss: 0.1984 - accuracy: 0.9320 - val_loss: 0.9439 - val_accuracy: 0.7949\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 48s 305ms/step - loss: 0.2030 - accuracy: 0.9291 - val_loss: 0.7967 - val_accuracy: 0.7995\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 48s 306ms/step - loss: 0.1801 - accuracy: 0.9320 - val_loss: 0.9923 - val_accuracy: 0.7601\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 48s 305ms/step - loss: 0.1514 - accuracy: 0.9430 - val_loss: 1.0252 - val_accuracy: 0.7775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25c498b340>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=50\n",
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea3d72ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Flowers.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3bea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "\n",
    "model=load_model(r'Flowers.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d53075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "test_img=image.load_img(r\"Flowers-Dataset/flowers/sunflower/44079668_34dfee3da1_n.jpg\",target_size=(180,180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f99fbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels=image.img_to_array(test_img)\n",
    "pixels=np.expand_dims(pixels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c24ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a2f7b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sunflower'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "categories[np.argmax(pred)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbe20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
